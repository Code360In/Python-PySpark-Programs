{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf00399",
   "metadata": {},
   "source": [
    "## Spark Dataframe\n",
    "We can manually create a PySpark DataFrame using toDF() and createDataFrame() methods, both these function takes different signatures in order to create DataFrame from existing RDD, list, and DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592683de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"testApp\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165fc04",
   "metadata": {},
   "source": [
    "#### Create DataFrame from RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1780383",
   "metadata": {},
   "source": [
    "|S.No.| Item     |  Input           | Command         | Output| Comment|\n",
    "|:----|:-------------|:------------------:|:-------------:|:-----:|:------|\n",
    "|  1  | Create DataFrame from RDD         |RDD| `rdd.toDF() `     | DF | |\n",
    "|  2  | Create DataFrame from RDD with columns         |RDD| `rdd.toDF(col_list)`     | DF | |\n",
    "|  3  | Create DataFrame from RDD using createDataFrame         |RDD| `spark.createDataFrame(rdd)`     | DF | |\n",
    "|  4  | Create DataFrame from RDD using createDataFrame with columns         |RDD| `spark.createDataFrame(rdd, schema=cols)`     | DF | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35ed4e",
   "metadata": {},
   "source": [
    "##### Using toDF() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bfcad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ((1, 2, 3),(4, 5, 6),(7, 8, 9))\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba7df36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df = rdd.toDF()\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b31b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| _1| _2| _3|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "|  4|  5|  6|\n",
      "|  7|  8|  9|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6433f514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      " |-- _3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b14ebe",
   "metadata": {},
   "source": [
    "##### With columns also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f79117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|COL1|COL2|COL3|\n",
      "+----+----+----+\n",
      "|   1|   2|   3|\n",
      "|   4|   5|   6|\n",
      "|   7|   8|   9|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = [\"COL1\",\"COL2\",\"COL3\"]\n",
    "df = rdd.toDF(cols)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d402c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COL1: long (nullable = true)\n",
      " |-- COL2: long (nullable = true)\n",
      " |-- COL3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9632a",
   "metadata": {},
   "source": [
    "##### Using createDataFrame()\n",
    "spark.createDataFrame(rdd).toDF(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a5807df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f0436fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| _1| _2| _3|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "|  4|  5|  6|\n",
      "|  7|  8|  9|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2cdeb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      " |-- _3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237d948",
   "metadata": {},
   "source": [
    "##### with columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f72bc496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd, schema=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01f1db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|COL1|COL2|COL3|\n",
      "+----+----+----+\n",
      "|   1|   2|   3|\n",
      "|   4|   5|   6|\n",
      "|   7|   8|   9|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b62f1c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COL1: long (nullable = true)\n",
      " |-- COL2: long (nullable = true)\n",
      " |-- COL3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ca082",
   "metadata": {},
   "source": [
    "#### Create DataFrame from List/Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25929339",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,\"John\",\"25\"), (2,\"Sam\",\"26\"), (3,\"Saul\", \"30\"),(4,\"Jorah\", \"30\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ad2b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bc01b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| _1|   _2| _3|\n",
      "+---+-----+---+\n",
      "|  1| John| 25|\n",
      "|  2|  Sam| 26|\n",
      "|  3| Saul| 30|\n",
      "|  4|Jorah| 30|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3810da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"id\",\"name\",\"age\"]\n",
    "df = spark.createDataFrame(data,schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "314cd4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| id| name|age|\n",
      "+---+-----+---+\n",
      "|  1| John| 25|\n",
      "|  2|  Sam| 26|\n",
      "|  3| Saul| 30|\n",
      "|  4|Jorah| 30|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd322b6",
   "metadata": {},
   "source": [
    "#### Create DataFrame with the Row type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e72c00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ad12d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[\n",
    "    Row(ID=1,NAME=\"John\",AGE=20),\n",
    "    Row(ID=2,NAME=\"Sam\",AGE=25)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8020aa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(AGE=20, ID=1, NAME='John'), Row(AGE=25, ID=2, NAME='Sam')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a8fe995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "624bf72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|AGE| ID|NAME|\n",
      "+---+---+----+\n",
      "| 20|  1|John|\n",
      "| 25|  2| Sam|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa691a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AGE: long (nullable = true)\n",
      " |-- ID: long (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc559a",
   "metadata": {},
   "source": [
    "#### Create DataFrame using Namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1560bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c224e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust = namedtuple(\"CUSTOMER\",[\"CUSTOMER_ID\",\"CUSTOMER_NAME\",\"CUSTOMER_ADDR\",\"CUSTOMER_EMAIL\",\"CUSTOMER_PHONE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e74bfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [cust(1,\"James\",\"639 Main St\",\"james@comapny.com\",\"504-845-1427\"),\n",
    "        cust(2,\"John\",\"#45 Main St\",\"john@comapny.com\",\"804-895-1427\"),\n",
    "        cust(3,\"Sam\",\"34 Center St\",\"sam@comapny.com\",\"704-895-1427\"),\n",
    "        cust(4,\"John\",\"322 New Horizon\",\"john@comapny.com\",\"604-895-1427\")\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f68be6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6973dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------+-----------------+--------------+\n",
      "|CUSTOMER_ID|CUSTOMER_NAME|  CUSTOMER_ADDR|   CUSTOMER_EMAIL|CUSTOMER_PHONE|\n",
      "+-----------+-------------+---------------+-----------------+--------------+\n",
      "|          1|        James|    639 Main St|james@comapny.com|  504-845-1427|\n",
      "|          2|         John|    #45 Main St| john@comapny.com|  804-895-1427|\n",
      "|          3|          Sam|   34 Center St|  sam@comapny.com|  704-895-1427|\n",
      "|          4|         John|322 New Horizon| john@comapny.com|  604-895-1427|\n",
      "+-----------+-------------+---------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13f23e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CUSTOMER_ID: long (nullable = true)\n",
      " |-- CUSTOMER_NAME: string (nullable = true)\n",
      " |-- CUSTOMER_ADDR: string (nullable = true)\n",
      " |-- CUSTOMER_EMAIL: string (nullable = true)\n",
      " |-- CUSTOMER_PHONE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b90bf8",
   "metadata": {},
   "source": [
    "#### Create DataFrame with StructType Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7edcc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,IntegerType,StringType,FloatType\n",
    "\n",
    "schema =StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"name\", StringType(), True),\n",
    "        ])\n",
    "\n",
    "df = spark.createDataFrame([(1, \"john\"),(2, \"sam\"),],schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c31c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1|john|\n",
      "|  2| sam|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d66dde12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d9772",
   "metadata": {},
   "source": [
    "##### Creating Empty Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d060a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = [\n",
    "    StructField(\"COL1\", FloatType(), True),\n",
    "    StructField(\"COL2\", StringType(), True),\n",
    "]\n",
    "schema = StructType(field)\n",
    "empty_df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76423add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|COL1|COL2|\n",
      "+----+----+\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empty_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46b8a69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COL1: float (nullable = true)\n",
      " |-- COL2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empty_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a867f67",
   "metadata": {},
   "source": [
    "#### Create a sample single-column Spark DataFrame in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9175dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([1,2,3,4,5], \"integer\").toDF(\"numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00596be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|numbers|\n",
      "+-------+\n",
      "|      1|\n",
      "|      2|\n",
      "|      3|\n",
      "|      4|\n",
      "|      5|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f80fcac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([1,2,3,4,5], IntegerType()).toDF(\"numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0189d0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|numbers|\n",
      "+-------+\n",
      "|      1|\n",
      "|      2|\n",
      "|      3|\n",
      "|      4|\n",
      "|      5|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71c87c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\"x\",\"y\",\"z\"], StringType()).toDF(\"char_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b6300ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|char_data|\n",
      "+---------+\n",
      "|        x|\n",
      "|        y|\n",
      "|        z|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb02b00",
   "metadata": {},
   "source": [
    "With name elements should be tuples and schema as sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae54668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(1, ), (2, ), (2,  )], [\"num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3807fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|num|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  2|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e23d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
